import tensorflow as tf
import pandas as pd
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

insurance3 = pd.read_csv("https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv")
insurance3.head()


ct3 = make_column_transformer((MinMaxScaler(),["age","bmi","children"]),(OneHotEncoder(handle_unknown="ignore"),["sex","smoker","region"]))

X3 = insurance3.drop("charges",axis=1)
y3 = insurance3["charges"]

X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2,random_state=42)

ct3.fit(X3_train)

X3_train_normalized = ct3.transform(X3_train)
X3_test_normalized  = ct3.transform(X3_test)


model3 = tf.keras.Sequential([
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(1)
])

model3.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.Adam(lr=0.1),
    metrics = ["mae"]
)

model3.fit(X_train_normalized,y_train,epochs = 200)

model3.evaluate(X_test_normalized,y_test)

